# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V6m8HK-ne4ZYqSs6FVIi89RBX7bxBMfV
"""

# Commented out IPython magic to ensure Python compatibility.
# hr_policy_chatbot_ultrasafe.py

# %pip install streamlit pypdf sentence-transformers faiss-cpu plotly pandas groq tiktoken
import os
import io
import json
import uuid
import hashlib
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Tuple
import time

import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from pypdf import PdfReader

try:
    import faiss  # type: ignore
except Exception:
    faiss = None

try:
    from groq import Groq
except Exception:
    Groq = None

# ------------------------------
# Config
# ------------------------------
EMBED_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
CHUNK_SIZE = 600
CHUNK_OVERLAP = 150
INDEX_DIR = "./indexes"
DOC_TEXT_DIR = os.path.join(INDEX_DIR, "doc_texts")
DEFAULT_TOP_K = 5

# ------------------------------
# Utilities
# ------------------------------
def ensure_dirs():
    os.makedirs(INDEX_DIR, exist_ok=True)
    os.makedirs(DOC_TEXT_DIR, exist_ok=True)

def hash_bytes(data: bytes) -> str:
    return hashlib.sha256(data).hexdigest()

def pdf_to_text(pdf_bytes: bytes) -> Tuple[str, List[int]]:
    reader = PdfReader(io.BytesIO(pdf_bytes))
    texts, page_starts, cursor = [], [], 0
    for page in reader.pages:
        page_starts.append(cursor)
        t = page.extract_text() or ""
        t = "\n".join(line.strip() for line in t.splitlines())
        texts.append(t)
        cursor += len(t) + 1
    return "\n".join(texts), page_starts

def save_doc_text(doc_id: str, text: str):
    path = os.path.join(DOC_TEXT_DIR, f"{doc_id}.txt")
    with open(path, "w", encoding="utf-8") as f:
        f.write(text)

def load_doc_text(doc_id: str) -> str:
    path = os.path.join(DOC_TEXT_DIR, f"{doc_id}.txt")
    return open(path, "r", encoding="utf-8").read() if os.path.exists(path) else ""

def chunk_text(text: str, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):
    chunks, i, n = [], 0, len(text)
    while i < n:
        j = min(n, i + chunk_size)
        chunks.append((text[i:j], i))
        i = j - overlap if j - overlap > i else j
    return chunks

@dataclass
class ChunkMeta:
    id: str
    doc_id: str
    start: int
    end: int
    page: int
    preview: str

class SimpleVectorIndex:
    def __init__(self, path: str, dim: int):
        self.index_path = path
        self.dim = dim
        self.faiss_index = None
        self.meta, self.id_map = {}, []

    def _create(self):
        self.faiss_index = faiss.IndexFlatIP(self.dim)

    def save(self):
        if self.faiss_index:
            faiss.write_index(self.faiss_index, self.index_path)
        with open(self.index_path + ".meta.json", "w") as f:
            json.dump({k: asdict(v) for k, v in self.meta.items()}, f)
        with open(self.index_path + ".ids", "w") as f:
            json.dump(self.id_map, f)

    def load(self) -> bool:
        if not os.path.exists(self.index_path):
            return False
        self.faiss_index = faiss.read_index(self.index_path)
        with open(self.index_path + ".meta.json") as f:
            self.meta = {k: ChunkMeta(**v) for k, v in json.load(f).items()}
        with open(self.index_path + ".ids") as f:
            self.id_map = json.load(f)
        return True

    def add(self, vectors, metas):
        if not self.faiss_index:
            self._create()
        vectors = vectors.astype("float32")
        vectors /= np.linalg.norm(vectors, axis=1, keepdims=True) + 1e-10
        self.faiss_index.add(vectors)
        for m in metas:
            self.id_map.append(m.id)
            self.meta[m.id] = m

    def search(self, query_vec, top_k=DEFAULT_TOP_K):
        q = query_vec.astype("float32")
        q /= np.linalg.norm(q) + 1e-10
        D, I = self.faiss_index.search(q.reshape(1, -1), top_k)
        return [(self.meta[self.id_map[idx]], float(score)) for score, idx in zip(D[0], I[0]) if idx != -1]

@st.cache_resource
def get_embedder():
    return SentenceTransformer(EMBED_MODEL_NAME)

def embed_texts(model, texts, batch_size=8):
    vecs = []
    for i in range(0, len(texts), batch_size):
        batch = [t for t in texts[i:i+batch_size] if t.strip()]
        if batch:
            vecs.append(model.encode(batch, convert_to_numpy=True))
    return np.vstack(vecs) if vecs else np.zeros((0, model.get_sentence_embedding_dimension()))

@st.cache_resource
def get_groq_client():
    api_key = os.getenv("GROQ_API_KEY", "")
    return Groq(api_key=api_key) if api_key and Groq else None

def call_llm(client, sys_prompt, user_prompt, model):
    if not client:
        return "[LLM disabled: no key]"
    res = client.chat.completions.create(
        model=model,
        temperature=0.2,
        max_tokens=600,
        messages=[{"role": "system", "content": sys_prompt},
                  {"role": "user", "content": user_prompt}],
    )
    return res.choices[0].message.content

def append_csv(path: str, row: Dict[str, Any]):
    df = pd.DataFrame([row])
    header = not os.path.exists(path)
    df.to_csv(path, mode="a", header=header, index=False, encoding="utf-8")

SYSTEM_PROMPT = (
    "You are an HR Policy Assistant. Use the CONTEXT to answer clearly and concisely. "
    "If context is incomplete try combining nearby chunks to give a full answer., "
    "but do not just say 'not found'."
)

# ------------------------------
# App
# ------------------------------
def main():
    st.set_page_config(page_title="HR Policy Assistant", page_icon="üß≠",layout="wide")
    st.title("üß≠ HR Policy Assistant Chatbot")
    st.markdown(
        """
        üëã Welcome to your **HR Policy Assistant**!
        Here‚Äôs how you can use this app:
        - üìÑ Upload your HR policy PDF from the sidebar, or load the default sample.
        - üîç Ask any HR-related questions (leave rules, benefits, code of conduct, etc.).
        - üìö Get answers backed by your HR documents with clear citations.
        - ‚úÖ Provide feedback on whether the answer was helpful.
        - üí° Suggest modifications or improvements to policies for review by the HR team.

        Start by uploading a policy document or using the sample from the sidebar ‚Üí
        """
    )

    ensure_dirs()

    with st.sidebar:
        files = st.file_uploader("Upload HR PDFs", type="pdf", accept_multiple_files=True)
        index_name = st.text_input("Index name", "hr_index")
        if st.button("Build Index"):
            embedder = get_embedder()
            index = SimpleVectorIndex(os.path.join(INDEX_DIR, index_name + ".faiss"),
                                      embedder.get_sentence_embedding_dimension())
            index._create()
            for f in files:
                data = f.read()
                doc_id = hash_bytes(data)[:12]
                text, starts = pdf_to_text(data)
                save_doc_text(doc_id, text)
                chunks = chunk_text(text)
                metas, texts = [], []
                for c, s in chunks:
                    cid = str(uuid.uuid4())[:8]
                    metas.append(ChunkMeta(cid, doc_id, s, s+len(c), 0, c[:100]))
                    texts.append(c)
                if texts:
                    vecs = embed_texts(embedder, texts)
                    index.add(vecs, metas)
            index.save()
            st.success("Index built")

    q = st.text_input("Ask HR Policy", placeholder="e.g., What are the official working hours?")

    # --- Sample question chips ---
    st.markdown("Try asking one of these:")
    cols = st.columns(3)
    samples = [
        "What are the official working hours?",
        "How many earned leaves do I get?",
        "What is the notice period for resignation?"
    ]
    for i, sample in enumerate(samples):
        if cols[i % 3].button(sample):
            q = sample

    if st.button("Ask") and q:
        embedder = get_embedder()
        index = SimpleVectorIndex(os.path.join(INDEX_DIR, index_name + ".faiss"),
                                  embedder.get_sentence_embedding_dimension())
        if not index.load():
            st.error("Index not found")
            return

        qvec = embed_texts(embedder, [q])[0]
        hits = index.search(qvec)

        context_parts = []
        for m, _ in hits:
            doc_text = load_doc_text(m.doc_id)
            snippet = doc_text[m.start:m.end] if doc_text else m.preview

            # --- NEW: stitch continuation if snippet is cut mid-sentence ---
            if doc_text and not snippet.strip().endswith(('.', '!', '?')):
                extra = doc_text[m.end:m.end+200]  # grab next ~200 chars
                snippet += " " + extra.strip().replace("\n", " ")

            context_parts.append(snippet)

        context = "\n\n".join(context_parts)

        client = get_groq_client()
        ans = call_llm(client, SYSTEM_PROMPT, f"CONTEXT:\n{context}\n\nQ: {q}", "llama-3.1-8b-instant")
        st.write(ans)

        # ==============================
        # Show Sources with snippets + page numbers
        # ==============================
        st.markdown("#### üìö Sources")
        for m, score in hits:
            st.markdown(
                f"- **Page {m.page + 1}** | *Relevance: {score:.2f}*  \n"
                f"Snippet: `{m.preview}`"
            )

        # ==============================
        # Feedback UI
        # ==============================
        st.markdown("#### Was this answer helpful?")
        col1, col2 = st.columns(2)
        if col1.button("üëç Yes"):
            append_csv("feedback_log.csv", {
                "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
                "question": q,
                "helpful": "Yes",
            })
            st.success("Thanks for your feedback!")
        if col2.button("üëé No"):
            append_csv("feedback_log.csv", {
                "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
                "question": q,
                "helpful": "No",
            })
            st.info("Feedback noted ‚Äî we'll use it to improve.")

        # ==============================
        # Suggestion UI
        # ==============================
        st.subheader("üí° Policy Suggestions")
        suggestion = st.text_area("Do you have any suggestions or modifications regarding this policy?", "")
        if st.button("Submit Suggestion"):
            if suggestion.strip():
                append_csv("suggestion_log.csv", {
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "question": q,
                    "answer": ans,
                    "suggestion": suggestion.strip(),
                })
                st.success("‚úÖ Your suggestion has been recorded and will be reviewed by the HR team.")
            else:
                st.warning("Please enter a suggestion before submitting.")


if __name__ == "__main__":
    main()